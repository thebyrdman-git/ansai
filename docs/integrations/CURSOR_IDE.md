# Cursor IDE Integration with ANSAI

## Overview

**ANSAI + Cursor = AI-powered automation directly in your IDE.**

This guide shows how to integrate ANSAI's AI capabilities into Cursor IDE workflows.

---

## ðŸŽ¯ What You Get

### Without Integration:
- Run ANSAI commands in terminal
- Switch between IDE and terminal
- Manual context switching

### With Cursor + ANSAI:
- **AI-powered automation from IDE**
- **Context-aware rules** generated by ANSAI
- **Natural language ops** in editor
- **Inline log analysis** with ANSAI AI
- **Automatic environment setup** when switching contexts

---

## ðŸš€ Quick Setup

### 1. Install ANSAI

```bash
git clone https://github.com/thebyrdman-git/ansai.git ~/.ansai
export PATH="$HOME/.ansai/bin:$PATH"
```

### 2. Configure Cursor to Use ANSAI

Create `.cursorrules` in your project root:

```yaml
# .cursorrules - ANSAI Integration

# AI Model Configuration
model: gpt-4
temperature: 0.7

# ANSAI Context
tools:
  - name: ansai-fabric
    description: "AI-powered text analysis and processing"
    command: "ansai-fabric"
    
  - name: ansai-context-switch
    description: "Switch ANSAI automation contexts"
    command: "ansai-context-switch"

# Automation Helpers
ai_assistants:
  log_analysis:
    trigger: "analyze logs"
    command: "journalctl -u {service} | ansai-fabric logs"
    
  root_cause:
    trigger: "what caused"
    command: "ansai-fabric analyze"
    
  summarize:
    trigger: "summarize"
    command: "ansai-fabric summarize"

# Context-Specific Rules
contexts:
  work:
    allowed_models: ["gpt-4"]
    data_privacy: strict
    external_apis: false
    
  personal:
    allowed_models: ["gpt-4", "claude", "local"]
    external_apis: true
```

### 3. Enable ANSAI Commands in Cursor

Add to your shell profile (`.bashrc` or `.zshrc`):

```bash
# ANSAI + Cursor Integration
export ANSAI_CURSOR_MODE=true
export CURSOR_AI_BACKEND="http://localhost:4000"  # LiteLLM proxy

# Quick aliases for Cursor terminal
alias analyze-logs="ansai-fabric logs"
alias ai-analyze="ansai-fabric analyze"
alias ai-explain="ansai-fabric explain"
```

---

## ðŸ’¡ Use Cases

### 1. AI-Powered Log Analysis in Editor

**Scenario:** Debugging a service failure

**In Cursor terminal:**
```bash
# View logs with AI analysis
journalctl -u myapp.service --since "1 hour ago" | ansai-fabric logs

# AI Output appears in terminal:
# Root Cause: Database connection pool exhausted
# Contributing: Traffic spike from new feature
# Recommendation: Increase pool size, add rate limiting
```

**In Cursor chat:**
```
You: "Analyze the logs for myapp.service"
Cursor: [Runs ansai-fabric logs automatically]
Cursor: "The AI identified a database connection pool issue..."
```

### 2. Context-Aware Development

**Scenario:** Switching between work and personal projects

**Before opening project:**
```bash
ansai-context-switch work
```

**ANSAI automatically:**
1. Updates Cursor rules for work context
2. Sets AI models to local-only (privacy)
3. Loads work-specific environment variables
4. Configures compliance mode

**Your `.cursorrules` is auto-generated:**
```yaml
# Auto-generated by ANSAI context: work
model: local-llama  # Privacy-first
external_apis: false
data_privacy: strict
compliance: enabled
```

### 3. Natural Language Automation

**In Cursor chat:**
```
You: "Why is CPU usage high?"
Cursor: [Triggers ANSAI]
ANSAI: [Analyzes metrics, correlates with logs]
Response: "CPU spike caused by backup job at 02:00. 
Recommend rescheduling to off-peak hours."
```

### 4. Inline Documentation with AI

**In editor, highlight complex error:**
```python
# SegmentationFault: address 0x7ffe5d7fff8 not mapped
```

**Right-click â†’ "Explain with ANSAI"**

**AI explains:**
```
This is a null pointer dereference. The code is trying to access
memory at address 0x7ffe5d7fff8 which hasn't been allocated.

Common causes:
1. Uninitialized pointer
2. Already-freed memory
3. Array out of bounds

In your code (line 42), check if the pointer is null before accessing.
```

---

## ðŸ”§ Advanced Integration

### Auto-Generate .cursorrules from Context

**Create a hook:**
```bash
# ~/.config/ansai/hooks/post-switch-work.sh
#!/bin/bash

# Generate Cursor rules for work context
cat > ~/work-projects/.cursorrules << EOF
# Auto-generated by ANSAI - Work Context
# Last updated: $(date)

model: local-llama
temperature: 0.5
external_apis: false

# ANSAI AI Backend
ai_backend: http://localhost:4000

# Work-specific constraints
data_privacy: strict
compliance_mode: enabled
allowed_models:
  - local-llama
  - granite-8b

# ANSAI Tools Available
tools:
  - ansai-fabric (AI text processing)
  - ansai-vault-read (secrets management)
  - ansai-context-switch (environment management)

# Prohibited Actions
prohibit:
  - External API calls to OpenAI/Anthropic
  - Sharing code snippets externally
  - Using cloud-based AI models
EOF

echo "âœ… Cursor rules updated for work context"
```

**Usage:**
```bash
ansai-context-switch work
# Automatically updates .cursorrules in work directory
```

### LiteLLM Proxy for Cursor

**Configure Cursor to use ANSAI's LiteLLM proxy:**

1. Start ANSAI LiteLLM proxy:
```bash
ansai-litellm-proxy
```

2. Configure Cursor settings:
```json
{
  "ai.backend": "openai-compatible",
  "ai.baseURL": "http://localhost:4000/v1",
  "ai.model": "gpt-4"
}
```

**Benefits:**
- Cost optimization (ANSAI routes to cheapest model)
- Automatic fallback if primary model fails
- Local models for sensitive code
- Usage tracking and budget limits

### Fabric Patterns in Cursor

**Create custom Cursor commands:**

**File:** `.cursor/commands.json`
```json
{
  "commands": [
    {
      "name": "Analyze with AI",
      "command": "ansai-fabric analyze",
      "description": "AI-powered code/log analysis"
    },
    {
      "name": "Explain Error",
      "command": "ansai-fabric explain",
      "description": "AI explains error messages"
    },
    {
      "name": "Summarize Changes",
      "command": "git diff | ansai-fabric summarize",
      "description": "AI summarizes your changes"
    },
    {
      "name": "Security Review",
      "command": "ansai-fabric security-review",
      "description": "AI security analysis"
    }
  ]
}
```

---

## ðŸŽ¨ Workflow Examples

### Example 1: AI-Assisted Debugging

**1. Service fails in production**
```bash
# In Cursor terminal
journalctl -u myapp.service | ansai-fabric logs
```

**2. AI identifies root cause**
```
Root Cause: Memory leak in worker process
Trigger: New deployment v2.1.0
Pattern: Memory grows 50MB/hour
ETA to OOM: 4 hours
```

**3. Ask Cursor for fix**
```
You: "How do I fix this memory leak?"
Cursor: [Uses AI context + code]
Response: "The leak is in the worker loop at line 145.
The buffer isn't being released. Add: buffer.clear()"
```

**4. Test fix**
```bash
# Deploy fix
ansible-playbook deploy.yml

# Verify with ANSAI
ansai-fabric verify-fix < new-logs.txt
```

### Example 2: Context-Aware Development

**Morning: Work Project**
```bash
ansai-context-switch work
cursor ~/work-project
```

**Cursor loads:**
- Work compliance rules
- Local-only AI models
- Work environment variables
- Strict data privacy mode

**Evening: Personal Project**
```bash
ansai-context-switch personal
cursor ~/personal-project
```

**Cursor loads:**
- Full AI model access
- External APIs enabled
- Personal preferences
- Creative mode

### Example 3: Natural Language DevOps

**In Cursor chat:**
```
You: "Deploy to staging"
Cursor: [Recognizes ANSAI command]
Cursor: "Running: ansible-playbook deploy-staging.yml"
[ANSAI executes with AI monitoring]
Cursor: "Deployed successfully. AI detected no anomalies."
```

```
You: "Why is the database slow?"
Cursor: [Triggers ANSAI analysis]
ANSAI: [Analyzes metrics, logs, queries]
Response: "Database slow due to missing index on users.email.
Add index: CREATE INDEX idx_users_email ON users(email);
Expected speedup: 95%"
```

---

## ðŸ” Security & Privacy

### Work Context (Strict Privacy)

```yaml
# .cursorrules (auto-generated by ANSAI)
context: work

ai_backend: local  # No cloud models
models:
  - ollama/llama2  # Runs on your machine
  - granite-8b     # Local model

prohibit:
  - external_api_calls
  - code_sharing
  - telemetry

compliance:
  - HIPAA
  - SOC2
  - GDPR
```

**ANSAI ensures:**
- All AI runs locally
- No code leaves your network
- Audit trail of all AI interactions
- Compliance-ready logging

### Personal Context (Full AI Access)

```yaml
# .cursorrules (auto-generated by ANSAI)
context: personal

ai_backend: http://localhost:4000  # LiteLLM proxy
models:
  - gpt-4           # Best quality
  - claude          # Alternative
  - ollama/llama2   # Local fallback

cost_optimization: enabled
external_apis: allowed
```

---

## ðŸ“Š Benefits Summary

| Feature | Without ANSAI | With ANSAI + Cursor |
|---------|---------------|---------------------|
| Log Analysis | Manual grep | AI root cause in chat |
| Context Switch | Manual setup | Auto-configured |
| AI Models | One provider | Multi-model routing |
| Privacy | Hope for the best | Context-enforced |
| Debugging | Stack Overflow | AI explains in editor |
| Cost | Full price | 70% optimized |

---

## ðŸš€ Getting Started Checklist

- [ ] Install ANSAI
- [ ] Start LiteLLM proxy (`ansai-litellm-proxy`)
- [ ] Create `.cursorrules` in your project
- [ ] Configure Cursor AI backend
- [ ] Test with `ansai-fabric` in terminal
- [ ] Create context-specific rules
- [ ] Set up auto-generation hooks
- [ ] Test context switching

---

## ðŸ†˜ Troubleshooting

### Cursor not finding ANSAI commands

**Solution:** Add to PATH in Cursor settings:
```json
{
  "terminal.integrated.env": {
    "PATH": "${env:HOME}/.ansai/bin:${env:PATH}"
  }
}
```

### LiteLLM proxy not connecting

**Solution:** Verify proxy is running:
```bash
ansai-litellm-proxy check
# If not running:
ansai-litellm-proxy start
```

### Context rules not updating

**Solution:** Check hook permissions:
```bash
chmod +x ~/.config/ansai/hooks/*.sh
ansai-context-switch work --verbose
```

---

## ðŸ“š Learn More

- **ANSAI Docs:** https://ansai.dev
- **Context Management:** [ansai-context-switch guide](../workflows/context-management/)
- **AI Integration:** [AI workflows guide](../workflows/ai-integration/)
- **Cursor Docs:** https://cursor.sh/docs

---

## ðŸ’¡ Pro Tips

1. **Use context switching** before opening projects in Cursor
2. **Route through LiteLLM** for cost optimization
3. **Create custom Fabric patterns** for your workflows
4. **Auto-generate .cursorrules** with ANSAI hooks
5. **Use local models** for sensitive code

---

**Part of the ANSAI Framework**  
Learn more: https://ansai.dev

**ANSAI + Cursor = AI-powered automation in your IDE** ðŸš€

